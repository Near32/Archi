model_id: 'ArchiTransformerTestModel'

input_stream_ids:
    "inputs:obs" : "observations:x"

modules:
    'LMModule':
        type: 'ArchiTransformerModule' 
        model_id: "togethercomputer/LLaMA-2-7B-32K"
        config:
            'quantize': True
            'bnb_config': 
                'load_in_4bit': True
                'bnb_4bit_use_double_quant': True
                'bnb_4bit_quant_type': 'nf4'
                'bnb_4bit_compute_dtype': 'bfloat16'
            'use_lora': True
            'lora_config':
                'r': 8
                'lora_alpha': 32
                'target_modules': ['q_proj','k_proj','v_proj','o_proj']
                'lora_dropout': 0.05
                'bias': 'none'
                'task_type': 'CAUSAL_LM'
            'generation_kwargs': 
               'max_length': 128
               'do_sample': True
               'temperature': 0.7 
               'repetition_penalty': 1.1 
               'stop_strings': ['\n']
               'top_p': 0.7 
               'top_k': 50
            'gradient_checkpointing': True
        use_cuda: True 
        input_stream_ids:
                inputs: 'inputs:obs'
        output_stream_ids:
                output: "inputs:LMModule:output"

pipelines:
        torso : []
        head: ['LMModule']

