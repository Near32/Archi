model_id: 'RL_ArchiTransformerTestModel'

hyperparameters:
    #hidden_dim: &hidden_dim 16384 #4096*action_dim
    hidden_dim: &hidden_dim 2304
    action_dim: &action_dim 4

input_stream_ids:
    "inputs:obs" : "observations:obs"
    #"inputs:obs" : "observations:x"

modules:
    'LMModule':
        type: 'ArchiTransformerModule' 
        model_id: "HuggingFaceTB/SmolLM-135M-Instruct"
        #model_id: "togethercomputer/LLaMA-2-7B-32K"
        config:
            'quantize': True
            'bnb_config': 
                'load_in_4bit': True
                'bnb_4bit_use_double_quant': True
                'bnb_4bit_quant_type': 'nf4'
                'bnb_4bit_compute_dtype': 'bfloat16'
            'use_lora': True
            'lora_config':
                'r': 8
                'lora_alpha': 32
                'target_modules': ['q_proj','k_proj','v_proj','o_proj']
                'lora_dropout': 0.05
                'bias': 'none'
                'task_type': 'CAUSAL_LM'
            'generation_kwargs': 
               'max_new_tokens': 1
               'do_sample': True
               'temperature': 0.7 
               'repetition_penalty': 1.1 
               'stop_strings': ['\n']
               'top_p': 0.7 
               'top_k': 50
            'gradient_checkpointing': True
        use_cuda: True 
        input_stream_ids:
                inputs: 'inputs:obs'
        output_stream_ids:
                output: "inputs:LMModule:output"

    'RLHead':
        type: RLCategoricalHeadModule
        state_dim: *hidden_dim
        action_dim: *action_dim
        noisy: False
        dueling: True
        action_logits_from_probs: True
        config: None
        input_stream_ids: 
            input0: "inputs:LMModule:inputs_last_token_last_hidden_states"
            action: "inputs:action"
            probs: 'inputs:LMModule:inputs_lprediction_probs'
            #legal_actions: "inputs:legal_actions"
            legal_actions: "inputs:LMModule:inputs_legal_choices"
        use_cuda: True

output_mappings:
        "ent" : "modules:RLHead:ent"
        "qa" : "modules:RLHead:qa"
        "log_a" : "modules:RLHead:log_a"

pipelines:
        torso : []
        head: ['LMModule', 'RLHead']

